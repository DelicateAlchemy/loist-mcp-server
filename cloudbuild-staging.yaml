# Google Cloud Build Configuration for Staging Environment
# Optimized staging deployment: Test â†’ Build â†’ Push â†’ Deploy (uses Artifact Registry)
# Staging embeds: https://staging.loist.io/embed/{audioId}
# Force rebuild: 2025-11-03

steps:
  # Step 1: Run Comprehensive Testing Suite (Staging)
  - name: 'python:3.11-slim'
    id: 'run-tests'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ðŸ§ª Running comprehensive testing suite (staging)..."

        # Install system dependencies for testing
        apt-get update && apt-get install -y --no-install-recommends \
          build-essential \
          libpq-dev \
          postgresql-client \
          && rm -rf /var/lib/apt/lists/*

        # Install Python dependencies
        pip install --upgrade pip
        pip install -r requirements.txt

        # Install additional test dependencies
        pip install pytest-cov pytest-xdist pytest-html

        # Create test results directory
        mkdir -p test-results coverage-reports

        # Run pytest with comprehensive coverage (relaxed threshold for staging)
        echo "ðŸ“Š Running pytest with coverage analysis (staging)..."
        python -m pytest \
          --cov=. \
          --cov-report=html:coverage-reports/htmlcov \
          --cov-report=xml:coverage-reports/coverage.xml \
          --cov-report=term-missing \
          --cov-fail-under=70 \
          --junitxml=test-results/junit.xml \
          --html=test-results/pytest-report.html \
          --self-contained-html \
          -v \
          --tb=short \
          --strict-markers \
          --disable-warnings \
          --maxfail=10 \
          --durations=10 \
          tests/

        # Store test exit code
        TEST_EXIT_CODE=$?
        echo "Test exit code: $TEST_EXIT_CODE"

        # Generate test summary
        echo "ðŸ“‹ Generating test summary..."
        cat > test-results/test-summary.json << EOF
        {
          "timestamp": "$(date -Iseconds)",
          "commit": "$COMMIT_SHA",
          "branch": "dev",
          "environment": "staging",
          "test_results": {
            "exit_code": "$TEST_EXIT_CODE",
            "coverage_required": 70,
            "parallel_execution": true
          }
        }
        EOF

        # For staging, only warn on test failures (don't block deployment)
        if [ "$TEST_EXIT_CODE" -ne 0 ]; then
          echo "âš ï¸ Tests failed with exit code $TEST_EXIT_CODE (staging - continuing deployment)"
          echo "Check test artifacts for details"
        else
          echo "âœ… All tests passed successfully"
        fi

  # Step 2: Run Static Analysis and Code Quality Checks (Staging)
  - name: 'python:3.11-slim'
    id: 'static-analysis'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "ðŸ” Running static analysis and code quality checks (staging)..."

        # Install system dependencies
        apt-get update && apt-get install -y --no-install-recommends \
          build-essential \
          && rm -rf /var/lib/apt/lists/*

        # Install Python dependencies
        pip install --upgrade pip
        pip install -r requirements.txt

        # Install static analysis tools
        pip install mypy flake8 black isort pylint bandit

        # Create analysis results directory
        mkdir -p analysis-results

        echo "ðŸ“ Running code formatting checks..."
        # Check black formatting (don't auto-fix in CI)
        python -m black --check --diff --color src/ tests/ scripts/

        echo "ðŸ”§ Running import sorting checks..."
        # Check import sorting
        python -m isort --check-only --diff --color src/ tests/ scripts/

        echo "ðŸ Running type checking..."
        # Run mypy type checking
        python -m mypy src/ --config-file mypy.ini

        echo "ðŸŽ¯ Running code quality checks..."
        # Run flake8
        python -m flake8 src/ tests/ --config .flake8

        echo "ðŸ›¡ï¸ Running security scanning..."
        # Run bandit security scanning
        python -m bandit -r src/ -f json -o analysis-results/security-scan.json

        echo "ðŸ“Š Generating analysis summary..."
        cat > analysis-results/analysis-summary.json << EOF
        {
          "timestamp": "$(date -Iseconds)",
          "commit": "$COMMIT_SHA",
          "branch": "dev",
          "environment": "staging",
          "tools_run": ["black", "isort", "mypy", "flake8", "bandit"]
        }
        EOF

        echo "âœ… Static analysis completed successfully"

  # Step 3: Build Docker image with optimized caching
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-image'
    args: [
      'build',
      # Target runtime stage (Alpine-based, more reliable than distroless)
      '--target', 'runtime',
      # Enable BuildKit for better performance and caching
      '--build-arg', 'BUILDKIT_INLINE_CACHE=1',
      # Use cache from previous builds
      '--cache-from', 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:latest',
      # Enable BuildKit cache mounts for faster builds
      '--build-arg', 'BUILDKIT_PROGRESS=plain',
      # Optimized tagging: commit SHA and latest only
      '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:${_COMMIT_SHA}',
      '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:latest',
      # Build context
      '.'
    ]
    env:
      - 'DOCKER_BUILDKIT=1'
    timeout: '600s'

  # Step 3: Store Test Artifacts and Reports (Staging)
  - name: 'gcr.io/cloud-builders/gsutil'
    id: 'store-artifacts'
    args: [
      '-m', 'cp', '-r',
      'test-results/',
      'coverage-reports/',
      'analysis-results/',
      'gs://$PROJECT_ID-build-artifacts-staging/$COMMIT_SHA/'
    ]
    waitFor: ['run-tests', 'static-analysis']
    allowFailure: true  # Don't fail build if artifact upload fails

  # Step 4: Push Docker image to Google Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-image'
    args: ['push', '--all-tags', 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging']
    waitFor: ['build-image']

  # Step 5: Ensure staging database exists
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'create-staging-db'
    entrypoint: 'bash'
    args: ['scripts/create-staging-database.sh']
    env:
      - 'CLOUDSDK_CORE_PROJECT=loist-music-library'

  # Step 6: Update staging secrets if needed
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'update-staging-secrets'
    entrypoint: 'bash'
    args: ['scripts/update-staging-secrets.sh']
    env:
      - 'CLOUDSDK_CORE_PROJECT=loist-music-library'

  # Step 7: Run database migrations (if needed)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'migrate-db'
    entrypoint: 'bash'
    args: ['scripts/migrate-db.sh']
    env:
      - 'CLOUDSDK_CORE_PROJECT=loist-music-library'

  # Step 8: Deploy to staging Cloud Run (uses built-in health checks)
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'deploy-staging'
    args:
      - 'run'
      - 'deploy'
      - 'music-library-mcp-staging'
      - '--image=us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:${_COMMIT_SHA}'
      - '--region=us-central1'
      - '--platform=managed'
      - '--allow-unauthenticated'
      - '--memory=1Gi'  # Smaller resources for staging
      - '--cpu=1'
      - '--timeout=300s'
      - '--concurrency=40'
      - '--max-instances=3'
      - '--min-instances=0'
      - '--port=8080'
      # Explicit command override to ensure correct startup (fallback if Dockerfile CMD is misinterpreted)
      - '--command=/usr/local/bin/python'
      - '--args=/app/src/server.py'
      - '--set-env-vars=SERVER_TRANSPORT=http,LOG_LEVEL=DEBUG,AUTH_ENABLED=false,ENABLE_CORS=true,CORS_ORIGINS=*,ENABLE_HEALTHCHECK=true'
      - '--set-env-vars=GCS_PROJECT_ID=$PROJECT_ID,SERVER_NAME=Music Library MCP - Staging'
      - '--set-env-vars=EMBED_BASE_URL=https://staging.loist.io'
      - '--set-env-vars=DB_NAME=loist_mvp_staging,DB_USER=music_library_user,DB_PORT=5432'
      - '--service-account=mcp-music-library-sa@$PROJECT_ID.iam.gserviceaccount.com'
      - '--update-secrets=DB_CONNECTION_NAME=${_DB_CONNECTION_NAME_STAGING}:latest'
      - '--update-secrets=DB_PASSWORD=${_DB_PASSWORD_STAGING}:latest'
      - '--update-secrets=GCS_BUCKET_NAME=${_GCS_BUCKET_NAME_STAGING}:latest'
      - '--update-secrets=BEARER_TOKEN=${_BEARER_TOKEN_STAGING}:latest'
      - '--quiet'
    waitFor: ['create-staging-db', 'update-staging-secrets', 'migrate-db']

# Automatically tag and push images
images:
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:${_COMMIT_SHA}'
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/music-library-repo/music-library-mcp-staging:latest'

# Build options and configuration
options:
  machineType: 'E2_HIGHCPU_8'  # Faster builds, same cost as default
  logging: CLOUD_LOGGING_ONLY

substitutions:
  _COMMIT_SHA: 'local-test'
  _DB_CONNECTION_NAME_STAGING: 'db-connection-name-staging'
  _DB_PASSWORD_STAGING: 'db-password-staging'
  _GCS_BUCKET_NAME_STAGING: 'gcs-bucket-name-staging'
  _BEARER_TOKEN_STAGING: 'mcp-bearer-token-staging'

# Build timeout (reduced from 15 to 10 minutes)
timeout: '600s'  # 10 minutes

tags:
  - 'music-library-mcp'
  - 'staging'
